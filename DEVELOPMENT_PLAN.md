# ğŸš€ DEVELOPMENT PLAN - YouTube Research Platform
**Date:** 2025-10-06
**Phase:** Backend API Development (Frontend TBD)
**Status:** In Progress

---

## ğŸ“Š **PROJECT OVERVIEW**

### **Objective**
Build subscription-based YouTube research automation backend that:
1. Downloads and analyzes YouTube videos
2. Extracts JTBD insights using multimodal AI
3. Provides tier-based API access (Standard/Pro/Admin)
4. **Prepares for future frontend integration** (not in current scope)

### **Current Scope: Backend Only**
- âœ… YouTube data ingestion
- âœ… Multimodal AI processing (Whisper + LLaVA + LLM)
- âœ… Tiered API model access
- âœ… JSON/CSV/HTML output
- âŒ Web UI (future phase)
- âŒ User authentication (future phase)
- âŒ Real-time dashboard (future phase)

---

## ğŸ¯ **YOUTUBE DATA SOURCE IMPLEMENTATION**

### **Status: Partially Implemented**

**What Exists:**
- âœ… `scripts/video_downloader.py` - YouTube download via yt-dlp
- âœ… YouTube API key in `.env`
- âœ… Whisper transcription working
- âœ… LLaVA visual analysis working

**What's Missing:**
- âŒ `core/data_sources/youtube.py` - Centralized YouTube module
- âŒ Search query API integration
- âŒ Playlist/channel batch processing
- âŒ Video metadata extraction
- âŒ Rate limit handling
- âŒ Deduplication logic

---

## ğŸ“ **REQUIRED FILE STRUCTURE**

### **Core Backend Structure**

```
video-research-platform/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data_sources/           # â† NEEDS CREATION
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ youtube.py          # YouTube API client
â”‚   â”‚   â””â”€â”€ validators.py       # Video/data validation
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ __init__.py         âœ… Exists
â”‚   â”‚   â”œâ”€â”€ perception.py       # â† NEEDS CREATION (Whisper + LLaVA)
â”‚   â”‚   â”œâ”€â”€ extraction.py       âœ… Exists (LLM JTBD)
â”‚   â”‚   â””â”€â”€ reporting.py        # â† NEEDS CREATION (HTML/JSON/CSV)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py         âœ… Exists
â”‚   â”‚   â”œâ”€â”€ model_registry.py   âœ… Exists (All API models)
â”‚   â”‚   â””â”€â”€ tier_manager.py     âœ… Exists (Subscription tiers)
â”‚   â”‚
â”‚   â””â”€â”€ api/                    # â† FUTURE: REST API endpoints
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ routes.py           # FastAPI routes
â”‚       â”œâ”€â”€ auth.py             # Authentication (future)
â”‚       â””â”€â”€ schemas.py          # Pydantic models
â”‚
â”œâ”€â”€ clients/
â”‚   â””â”€â”€ 3m_lighting/
â”‚       â”œâ”€â”€ config.yaml         âœ… Exists
â”‚       â”œâ”€â”€ prompts.yaml        âœ… Exists
â”‚       â””â”€â”€ search_queries.yaml # â† NEEDS CREATION
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_research.py         # â† NEEDS CREATION (Main pipeline)
â”‚   â”œâ”€â”€ video_downloader.py     âœ… Exists
â”‚   â””â”€â”€ validate_setup.py       # â† NEEDS CREATION
â”‚
â””â”€â”€ config/
    â”œâ”€â”€ model_paths.yaml        âœ… Exists
    â””â”€â”€ model_tiers.yaml        âœ… Exists
```

---

## ğŸ”§ **PHASE 1: YOUTUBE DATA SOURCE (CURRENT)**

### **Module: `core/data_sources/youtube.py`**

**Purpose:** Centralized YouTube API interaction

**Required Functions:**
```python
class YouTubeDataSource:
    def __init__(self, api_key: str):
        """Initialize YouTube Data API v3 client"""

    def search_videos(
        self,
        query: str,
        max_results: int = 50,
        order: str = 'relevance'
    ) -> List[Dict]:
        """
        Search YouTube videos by keyword

        Returns:
            List of video metadata (id, title, description, stats)
        """

    def get_video_metadata(self, video_id: str) -> Dict:
        """
        Get detailed metadata for a video

        Returns:
            {
                'id': str,
                'title': str,
                'description': str,
                'channel': str,
                'published_at': str,
                'duration': int (seconds),
                'view_count': int,
                'like_count': int,
                'comment_count': int
            }
        """

    def download_video(
        self,
        video_id: str,
        output_dir: Path,
        quality: str = 'best'
    ) -> Path:
        """
        Download video using yt-dlp

        Returns:
            Path to downloaded video file
        """

    def extract_audio(
        self,
        video_path: Path,
        output_dir: Path
    ) -> Path:
        """
        Extract audio track to WAV for Whisper

        Returns:
            Path to audio file
        """

    def is_duplicate(
        self,
        video_id: str,
        existing_videos: List[str]
    ) -> bool:
        """Check if video already processed"""
```

**Dependencies:**
```python
import os
from pathlib import Path
from typing import List, Dict, Optional
import yt_dlp
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
```

**Integration Points:**
- Input: Search queries from `clients/{client}/search_queries.yaml`
- Output: Video files + metadata to `data/{client}/videos/`
- Used by: `core/pipeline/perception.py`

---

## ğŸ”§ **PHASE 2: PERCEPTION PIPELINE**

### **Module: `core/pipeline/perception.py`**

**Purpose:** Multimodal analysis (audio + visual)

**Required Functions:**
```python
class PerceptionPipeline:
    def __init__(self, model_registry: ModelRegistry):
        """Initialize Whisper + LLaVA models"""

    def analyze_video(
        self,
        video_path: Path,
        output_dir: Path
    ) -> Dict:
        """
        Full multimodal analysis

        Returns:
            {
                'transcription': {...},  # Whisper output
                'visual_analyses': [...],  # LLaVA frames
                'metadata': {...}
            }
        """

    def transcribe_audio(
        self,
        audio_path: Path
    ) -> Dict:
        """
        Whisper transcription

        Returns:
            {
                'text': str,
                'segments': [
                    {
                        'start': float,
                        'end': float,
                        'text': str
                    }
                ],
                'language': str,
                'duration': float
            }
        """

    def analyze_frames(
        self,
        video_path: Path,
        interval: int = 30
    ) -> List[Dict]:
        """
        LLaVA visual analysis at intervals

        Returns:
            [
                {
                    'timestamp': float,
                    'frame_path': str,
                    'analysis': str (LLaVA description)
                }
            ]
        """

    def extract_keyframes(
        self,
        video_path: Path,
        output_dir: Path,
        interval: int = 30
    ) -> List[Path]:
        """Extract frames every N seconds"""
```

**Integration Points:**
- Input: Video files from YouTube data source
- Output: Analysis JSON to `data/{client}/analysis/{video_id}/`
- Used by: `core/pipeline/extraction.py`

---

## ğŸ”§ **PHASE 3: REPORTING MODULE**

### **Module: `core/pipeline/reporting.py`**

**Purpose:** Generate client deliverables

**Required Functions:**
```python
class ReportGenerator:
    def __init__(self, client_config: Dict):
        """Initialize with client branding/config"""

    def generate_html_report(
        self,
        insights: List[Dict],
        output_path: Path
    ) -> Path:
        """
        HTML report with insights

        Sections:
        - Executive summary
        - Pain points (table + visualizations)
        - Solutions demonstrated
        - 3M product adjacencies
        - Verbatim quotes
        - Video references
        """

    def generate_json_export(
        self,
        insights: List[Dict],
        output_path: Path
    ) -> Path:
        """
        Structured JSON for API consumption

        Format:
        {
            "client": str,
            "generated_at": ISO datetime,
            "videos_analyzed": int,
            "insights": {
                "pain_points": [...],
                "solutions": [...],
                "adjacencies": [...],
                "verbatims": [...]
            },
            "metadata": {...}
        }
        """

    def generate_csv_export(
        self,
        insights: List[Dict],
        output_dir: Path
    ) -> List[Path]:
        """
        CSV files for Excel analysis

        Files:
        - pain_points.csv
        - solutions.csv
        - adjacencies.csv
        - verbatims.csv
        """
```

**Integration Points:**
- Input: Extracted insights from `extraction.py`
- Output: Reports to `clients/{client}/reports/`
- **API-Ready:** JSON output format ready for REST API

---

## ğŸ”§ **PHASE 4: MAIN PIPELINE ORCHESTRATOR**

### **Script: `scripts/run_research.py`**

**Purpose:** Main entry point for research execution

**CLI Interface:**
```bash
# Run full research pipeline
python scripts/run_research.py \
    --client 3m_lighting \
    --mode production \
    --tier admin \
    --max-videos 100

# Preflight test (3 videos)
python scripts/run_research.py \
    --client 3m_lighting \
    --mode preflight \
    --tier pro

# Search only (no processing)
python scripts/run_research.py \
    --client 3m_lighting \
    --search-only \
    --save-results queries.json
```

**Workflow:**
```python
def main(client: str, mode: str, tier: str, max_videos: int):
    """
    1. Load client configuration
    2. Search YouTube videos
    3. Download + deduplicate
    4. Perception analysis (Whisper + LLaVA)
    5. JTBD extraction (tier-based LLM)
    6. Generate reports
    7. Save to archives
    """
```

**Progress Tracking:**
```python
# Real-time progress output
ğŸ“¥ Searching YouTube...
   Found 127 videos matching queries
   Filtered to 100 (deduplicated, sorted by relevance)

ğŸ“¦ Downloading videos... [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘] 80/100 (12 min remaining)

ğŸ§  Processing with Gemini 2.0 Flash (Pro tier)
   Video 1/100: LED Shelf Lighting [âœ“ 28s]
   Video 2/100: Under Cabinet Install [âœ“ 31s]
   ...

ğŸ“Š Generating reports...
   âœ“ HTML: reports/3m_lighting_2025-10-06.html
   âœ“ JSON: reports/3m_lighting_2025-10-06.json
   âœ“ CSV: reports/pain_points.csv

âœ… Complete! 100 videos analyzed in 1.2 hours
```

---

## ğŸ”§ **PHASE 5: API PREPARATION (Backend Ready for Frontend)**

### **Module: `core/api/routes.py`** (Future Phase)

**Purpose:** REST API endpoints for frontend

**Planned Endpoints:**
```python
# Research Jobs
POST   /api/research/create
GET    /api/research/{job_id}
GET    /api/research/{job_id}/progress
GET    /api/research/{job_id}/results

# Video Management
GET    /api/videos/search
POST   /api/videos/analyze
GET    /api/videos/{video_id}/insights

# Client Management
GET    /api/clients/{client_id}/config
GET    /api/clients/{client_id}/reports
POST   /api/clients/{client_id}/queries

# Subscription Tiers
GET    /api/tiers
GET    /api/user/tier
GET    /api/user/usage
```

**Response Format (JSON):**
```json
{
  "status": "success|error|processing",
  "data": {...},
  "metadata": {
    "tier": "pro",
    "cost": 0.75,
    "processing_time": 28.5
  }
}
```

**Authentication (Future):**
- JWT tokens
- API key authentication
- Tier validation middleware

---

## ğŸ“Š **DATA FLOW DIAGRAM**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YouTube API    â”‚
â”‚  (Data Source)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Video Download  â”‚  â† scripts/video_downloader.py
â”‚ + Metadata      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Perception    â”‚  â† core/pipeline/perception.py
â”‚ Whisper + LLaVA â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Extraction    â”‚  â† core/pipeline/extraction.py
â”‚  (Tier-based)   â”‚  â† core/models/tier_manager.py
â”‚ Llama|Gemini|..â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Reporting     â”‚  â† core/pipeline/reporting.py
â”‚ HTML/JSON/CSV   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client Reports â”‚
â”‚  + JSON API     â”‚  â†’ Future: REST API endpoints
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… **IMPLEMENTATION CHECKLIST**

### **Phase 1: YouTube Data Source (Priority 1)**
- [ ] Create `core/data_sources/__init__.py`
- [ ] Implement `core/data_sources/youtube.py`
  - [ ] Search API integration
  - [ ] Video metadata extraction
  - [ ] Download wrapper (yt-dlp)
  - [ ] Audio extraction (FFmpeg)
  - [ ] Deduplication logic
- [ ] Create `clients/3m_lighting/search_queries.yaml`
- [ ] Test: Search â†’ Download â†’ Validate

### **Phase 2: Perception Pipeline (Priority 2)**
- [ ] Create `core/pipeline/perception.py`
  - [ ] Whisper transcription
  - [ ] LLaVA frame analysis
  - [ ] Temporal alignment
  - [ ] JSON output format
- [ ] Integrate with model_registry.py
- [ ] Test: Video â†’ Transcript + Visual analysis

### **Phase 3: Reporting Module (Priority 3)**
- [ ] Create `core/pipeline/reporting.py`
  - [ ] HTML template (Jinja2)
  - [ ] JSON export (API-ready)
  - [ ] CSV export (Excel-ready)
- [ ] Add client branding support
- [ ] Test: Insights â†’ HTML/JSON/CSV

### **Phase 4: Main Pipeline (Priority 4)**
- [ ] Create `scripts/run_research.py`
  - [ ] CLI argument parsing
  - [ ] Orchestration logic
  - [ ] Progress tracking
  - [ ] Error handling
- [ ] Integrate tier_manager for model selection
- [ ] Add cost tracking per tier
- [ ] Test: End-to-end pipeline

### **Phase 5: API Prep (Priority 5 - Future)**
- [ ] Design REST API schema
- [ ] Create FastAPI routes
- [ ] Add authentication middleware
- [ ] Document API endpoints
- [ ] Create OpenAPI spec

---

## ğŸ“š **EXISTING VS NEW DOCUMENTATION**

### **Documents to KEEP (Current State)**
1. âœ… `README.md` - High-level overview
2. âœ… `TIERED_MODEL_DEPLOYMENT.md` - Subscription system (latest)
3. âœ… `MODEL_EVALUATION_FINAL_REPORT.md` - Model comparison results
4. âœ… `config/model_tiers.yaml` - Tier configuration (active)

### **Documents to ARCHIVE (Superseded)**
1. âš ï¸ `COMPLETE_MODEL_ANALYSIS.md` â†’ Superseded by `MODEL_EVALUATION_FINAL_REPORT.md`
2. âš ï¸ `MODEL_OPTIMIZATION_REPORT.md` â†’ Superseded by `MODEL_EVALUATION_FINAL_REPORT.md`
3. âš ï¸ `PHASE_2_COMPLETE.md` â†’ Historical, move to docs/archive/
4. âš ï¸ `OBJECTIVE_EVALUATION.md` â†’ Historical, move to docs/archive/

### **Documents to CREATE**
1. ğŸ†• `DEVELOPMENT_PLAN.md` (this file) - Current dev roadmap
2. ğŸ†• `API_SPECIFICATION.md` - REST API design (future phase)
3. ğŸ†• `YOUTUBE_DATA_SOURCE.md` - YouTube integration details

---

## ğŸ¯ **IMMEDIATE NEXT STEPS**

### **This Session:**
1. Create `core/data_sources/youtube.py`
2. Create `clients/3m_lighting/search_queries.yaml`
3. Test YouTube search + download
4. Archive superseded documentation

### **Next Session:**
1. Implement `core/pipeline/perception.py`
2. Create `scripts/run_research.py`
3. End-to-end pipeline test
4. Generate first production report

---

## ğŸš¨ **FRONTEND FUTURE CONSIDERATIONS**

### **API-Ready Design Principles**
1. **JSON-First:** All outputs in structured JSON
2. **Stateless:** Backend doesn't track frontend state
3. **Idempotent:** Safe to retry operations
4. **Paginated:** Large result sets paginated
5. **Versioned:** API v1, v2 compatibility

### **Planned Frontend Features (Out of Scope Now)**
- Dashboard for job monitoring
- User authentication/registration
- Tier selection UI
- Report viewer (HTML/PDF)
- Video player with insight timeline
- Search query builder
- Cost/usage analytics

### **Backend â†’ Frontend Data Contract**
```json
{
  "research_job": {
    "id": "uuid",
    "client": "3m_lighting",
    "status": "completed",
    "tier": "pro",
    "videos_analyzed": 100,
    "total_cost": 0.75,
    "created_at": "2025-10-06T12:00:00Z",
    "completed_at": "2025-10-06T13:15:00Z"
  },
  "insights": {
    "pain_points": [...],
    "solutions": [...],
    "adjacencies": [...]
  },
  "reports": {
    "html_url": "/reports/3m_lighting_2025-10-06.html",
    "json_url": "/api/research/job-123/export.json",
    "csv_url": "/api/research/job-123/export.csv"
  }
}
```

---

**Status:** âœ… Backend design complete, YouTube module implementation ready to begin
**Next Milestone:** YouTube data source + perception pipeline (Phases 1-2)
**ETA:** 2-3 hours development + testing
