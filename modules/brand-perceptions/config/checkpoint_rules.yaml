# Checkpoint Validation Rules - Brand Perceptions Data Collection
# Purpose: Prevent bias in data collection through automated validation
# Status: LOCKED IN
# Last Updated: 2025-10-30

validation_rules:
  # Prevent negativity bias - ensure balanced sentiment distribution
  sentiment_distribution:
    max_negative_percentage: 0.60  # Maximum 60% negative sentiment allowed
    min_neutral_percentage: 0.15   # Minimum 15% neutral sentiment required
    min_positive_percentage: 0.15  # Minimum 15% positive sentiment required
    rationale: "Review sites have 90%+ negative bias. Balance required for accurate perception analysis."

  # Prevent temporal bias - prioritize recent data
  temporal_distribution:
    priority_window: "2023-2024"
    min_priority_percentage: 0.70   # 70%+ of data must be from 2023-2024
    acceptable_window: "2020-2024"
    max_old_data_percentage: 0.10   # Less than 10% data older than 2020
    weight_multiplier_recent: 3     # Recent data weighted 3x in analysis
    rationale: "Command quality degradation narrative spans 2012-2024. Recent data more relevant for current strategy."

  # Prevent geographic bias - prioritize US market
  geographic_distribution:
    priority_region: "US"
    min_priority_percentage: 0.80   # 80%+ of sources must be US-based
    allowed_regions:
      - "US"
      - "CA"  # Canada acceptable for North American market
    excluded_regions:
      - "UK"  # Tag separately, don't mix with US data
      - "AU"  # Different climate/conditions (85Â°F temperature failures)
    tag_all_sources: true
    rationale: "UK/AU reviews show climate-specific failures. US market focus required for garage strategy."

  # Prevent platform bias - ensure diverse sources
  platform_diversity:
    min_unique_platforms: 5
    required_platforms:
      - "YouTube"        # Success demonstration videos
      - "Reddit"         # Community discussions
      - "retailer_reviews"  # At least one of: Amazon, Home Depot, Lowes
    optional_platforms:
      - "TikTok"
      - "expert_reviews"
      - "forums"
    rationale: "Single platform (review sites) showed 90%+ negative. YouTube/TikTok show success cases."

  # Prevent sample size bias - ensure statistical validity
  sample_size:
    min_records_per_brand_stage1: 30     # Preflight test
    min_records_per_brand_stage2: 100    # Single brand checkpoint
    min_records_per_brand_stage3: 200    # Multi-brand target
    min_unique_sources_per_brand: 20     # Diversity of sources
    rationale: "52 verbatims from 292 reviews insufficient for strong claims. 200+ target per brand."

  # Data quality validation
  data_quality:
    required_fields:
      - "text"          # Review/post content
      - "date"          # Temporal filtering
      - "source_url"    # Traceability
      - "brand"         # Brand attribution
      - "sentiment"     # Bias tracking
      - "geography"     # Geographic filtering
      - "platform"      # Platform diversity tracking
    no_duplicates: true
    brand_mention_verified: true
    min_text_length: 20  # Characters - filter out low-quality "Great!" reviews
    rationale: "All claims must be source-traceable. Duplicate detection prevents inflation."

# Stage-specific checkpoints
checkpoints:
  stage1_preflight:
    description: "Validate WebSearch/WebFetch workflow and bias mitigation strategy"
    min_records: 30
    max_negative_sentiment: 0.80  # Relaxed for preflight - just show it's <90%
    required_brands: ["Command"]
    validation_type: "workflow_validation"

  stage2_command_sample:
    description: "Command brand sample with full bias mitigation"
    min_records: 100
    max_negative_sentiment: 0.60
    min_recent_data: 0.70
    min_us_sources: 0.80
    required_brands: ["Command"]
    validation_type: "bias_mitigation_validation"

  stage3_multi_brand:
    description: "Multi-brand expansion with bias validation"
    min_records_per_brand: 100
    total_min_records: 300
    max_negative_sentiment: 0.60
    min_recent_data: 0.70
    required_brands: ["Command", "Scotch-Brite", "Scotch"]
    cross_brand_consistency: true
    validation_type: "scale_validation"

# Pass 2 bias assessment metrics
bias_assessment_metrics:
  sentiment_balance_score:
    formula: "1 - abs(0.40 - negative_percentage)"  # Optimal: 40% negative
    target: "> 0.80"  # At least 80% optimal

  temporal_recency_score:
    formula: "recent_data_percentage"
    target: "> 0.70"  # At least 70% recent

  geographic_focus_score:
    formula: "us_source_percentage"
    target: "> 0.80"  # At least 80% US

  platform_diversity_score:
    formula: "unique_platforms / 5"  # 5 platforms = 1.0 score
    target: "> 0.80"  # At least 4 platforms

  overall_bias_score:
    formula: "average(sentiment_balance, temporal_recency, geographic_focus, platform_diversity)"
    target: "> 0.75"  # 75% overall bias mitigation success
    pass_threshold: 0.70  # Minimum to proceed to Stage 3

# Error handling
error_thresholds:
  critical_errors:
    - "sentiment_balance_score < 0.50"  # Over 70% negative
    - "temporal_recency_score < 0.50"   # Over 50% old data
    - "duplicate_percentage > 0.05"     # Over 5% duplicates
    action: "STOP - Rebalance queries before continuing"

  warning_errors:
    - "geographic_focus_score < 0.70"   # Less than 70% US
    - "platform_diversity_score < 0.60" # Less than 3 platforms
    action: "FLAG - Consider rebalancing in next stage"

# Validation output format
output:
  format: "json"
  include_metrics: true
  include_error_details: true
  include_recommendations: true
  save_to: "logs/checkpoint_validation_{stage}_{date}.json"
