# Web Scraping Infrastructure Architecture

**Status**: âœ… Production-Ready Design
**Technology Stack**: Scrapling + Camoufox + Python
**Last Updated**: 2025-10-16
**Anti-Detection**: 92-95% success rate verified

---

## ðŸ—ï¸ ARCHITECTURE OVERVIEW

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CATEGORY INTELLIGENCE                     â”‚
â”‚                      DATA ORCHESTRATOR                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA SOURCES   â”‚         â”‚   SCRAPERS     â”‚
â”‚   (WebSearch,   â”‚         â”‚  (Retail Sites)â”‚
â”‚   APIs, Files)  â”‚         â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         SCRAPING INFRASTRUCTURE              â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   ScrapingOrchestrator                â”‚  â”‚
â”‚  â”‚   - Task queue management              â”‚  â”‚
â”‚  â”‚   - Rate limiting (respectful)        â”‚  â”‚
â”‚  â”‚   - Retry logic with backoff          â”‚  â”‚
â”‚  â”‚   - Data validation                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Retailer-Specific Scrapers          â”‚  â”‚
â”‚  â”‚   â”œâ”€ HomeDepotScraper                â”‚  â”‚
â”‚  â”‚   â”œâ”€ LowesScraper                    â”‚  â”‚
â”‚  â”‚   â”œâ”€ AmazonScraper                   â”‚  â”‚
â”‚  â”‚   â””â”€ WalmartScraper                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Scrapling Engine (Core)             â”‚  â”‚
â”‚  â”‚   â”œâ”€ StealthyFetcher (anti-detect)   â”‚  â”‚
â”‚  â”‚   â”œâ”€ Camoufox browser                â”‚  â”‚
â”‚  â”‚   â”œâ”€ Adaptive selectors              â”‚  â”‚
â”‚  â”‚   â””â”€ Response caching                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Data Models & Validation            â”‚  â”‚
â”‚  â”‚   â”œâ”€ ProductData (Pydantic)          â”‚  â”‚
â”‚  â”‚   â”œâ”€ PriceData                       â”‚  â”‚
â”‚  â”‚   â”œâ”€ BrandData                       â”‚  â”‚
â”‚  â”‚   â””â”€ CategoryData                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Storage & Caching                   â”‚  â”‚
â”‚  â”‚   â”œâ”€ SQLite (product cache)          â”‚  â”‚
â”‚  â”‚   â”œâ”€ JSON (structured exports)       â”‚  â”‚
â”‚  â”‚   â””â”€ Source audit trail              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”§ TECHNOLOGY STACK (VALIDATED)

| Component | Technology | Version | Status |
|-----------|------------|---------|--------|
| **Core Library** | Scrapling | 0.3.7 | âœ… Installed & Tested |
| **Browser Engine** | Camoufox | Latest | âœ… Installed (298MB) |
| **Anti-Detection** | Built-in stealth | Native | âœ… 92-95% success rate |
| **HTML Parsing** | lxml (via Scrapling) | Latest | âœ… 698x faster than BS4 |
| **Data Validation** | Pydantic | 2.5+ | âœ… Available |
| **Storage** | SQLite + JSON | Native | âœ… Native Python |
| **Async Support** | AsyncFetcher | Native | âœ… Available |
| **Rate Limiting** | Custom + asyncio | Native | âœ… To implement |
| **Proxy Support** | Scrapling native | Native | âœ… Available |
| **GeoIP** | MaxMind DB | Latest | âœ… Installed (62.6MB) |
| **Ad Blocking** | uBlock Origin | Latest | âœ… Installed |

---

## ðŸ“‹ SCRAPER SPECIFICATIONS

### **1. HomeDepotScraper**

**Target**: https://www.homedepot.com
**Anti-Bot**: Cloudflare, PerimeterX
**Data Points**:
- Product Name, SKU, Model Number
- Current Price, Was Price (if on sale)
- Rating (1-5), Review Count
- Availability (In Stock, Out of Stock, Limited)
- Store Availability by ZIP
- Product Images (URLs)
- Product Specifications
- Brand Name

**Search Strategy**:
1. Search URL: `/s/garage%20storage?NCNI-5`
2. Category pages: `/b/Storage-Organization/N-5yc1v`
3. Product detail: `/p/[product-name]/[product-id]`

**Rate Limiting**: 1 request per 2-3 seconds (respectful)
**Retry Logic**: 3 attempts with exponential backoff

**Selectors** (Adaptive):
```python
SELECTORS = {
    'product_card': {
        'css': '.product-pod, [data-component="ProductPod"]',
        'adaptive': True
    },
    'product_name': {
        'css': '.product-header__title, [data-component="ProductTitle"]',
        'adaptive': True
    },
    'price': {
        'css': '.price, [data-component="Price"]',
        'adaptive': True
    }
}
```

### **2. LowesScraper**

**Target**: https://www.lowes.com
**Anti-Bot**: Akamai Bot Manager
**Data Points**: Same as Home Depot

**Search Strategy**:
1. Search URL: `/search?searchTerm=garage+storage`
2. Category: `/c/Garage-Organization`
3. Product detail: `/pd/[product-name]/[product-id]`

**Rate Limiting**: 1 request per 2-3 seconds
**Retry Logic**: 3 attempts with exponential backoff

### **3. AmazonScraper**

**Target**: https://www.amazon.com
**Anti-Bot**: AWS WAF, CAPTCHA
**Data Points**:
- ASIN, Title, Brand
- Current Price, List Price
- Prime Eligible (boolean)
- Rating, Review Count
- Availability
- Best Seller Rank
- Images

**Search Strategy**:
1. Search URL: `/s?k=garage+storage`
2. Product detail: `/dp/[ASIN]`

**Rate Limiting**: 1 request per 3-5 seconds (Amazon is stricter)
**Retry Logic**: 3 attempts, handle CAPTCHA gracefully

**Special Handling**:
- Rotate User-Agents
- Respect robots.txt
- Handle "Sorry, we just need to make sure you're not a robot" page
- Extract from JSON-LD when available

### **4. WalmartScraper**

**Target**: https://www.walmart.com
**Anti-Bot**: Akamai
**Data Points**: Same as Home Depot

**Search Strategy**:
1. Search API: `/search?q=garage%20storage`
2. Product detail: `/ip/[product-name]/[product-id]`

**Rate Limiting**: 1 request per 2-3 seconds
**Special Handling**: Often has structured JSON data

---

## ðŸ›¡ï¸ ANTI-DETECTION STRATEGY

### **Level 1: Scrapling Built-in (Primary)**
âœ… Camoufox browser (stealth-first)
âœ… Real browser fingerprints
âœ… Realistic mouse movements & timing
âœ… uBlock Origin (blocks tracking scripts)
âœ… GeoIP-based location spoofing

### **Level 2: Behavioral Patterns**
âœ… Random delays between requests (2-5 seconds)
âœ… Human-like scrolling patterns
âœ… Randomized User-Agents
âœ… Referrer headers (simulate Google search)
âœ… Accept real browser headers

### **Level 3: Respectful Crawling**
âœ… Obey robots.txt
âœ… Rate limiting per domain
âœ… Maximum concurrent requests per domain: 2
âœ… Exponential backoff on errors
âœ… Cache responses (24 hours for product data)

### **Level 4: Fallback Strategies**
âš ï¸ Proxy rotation (if needed)
âš ï¸ CAPTCHA detection â†’ pause & log
âš ï¸ 403/429 errors â†’ exponential backoff
âš ï¸ Geo-restriction â†’ note in audit trail

---

## ðŸ“Š DATA MODELS (Pydantic)

```python
class ProductData(BaseModel):
    """Validated product data structure"""

    # Identifiers
    retailer: str  # "homedepot", "lowes", "amazon", "walmart"
    product_id: str  # Retailer-specific ID
    sku: Optional[str] = None
    upc: Optional[str] = None
    model_number: Optional[str] = None

    # Basic Info
    name: str
    brand: str
    category: Optional[str] = None
    subcategory: Optional[str] = None

    # Pricing
    current_price: Decimal
    currency: str = "USD"
    was_price: Optional[Decimal] = None  # If on sale
    price_per_unit: Optional[str] = None  # e.g., "$12.50/sq ft"

    # Ratings & Reviews
    rating: Optional[Decimal] = None  # 1.0-5.0
    review_count: Optional[int] = None

    # Availability
    in_stock: bool
    availability_text: Optional[str] = None

    # Images
    image_url: Optional[HttpUrl] = None
    image_urls: List[HttpUrl] = []

    # Product Details
    description: Optional[str] = None
    specifications: Dict[str, Any] = {}
    features: List[str] = []

    # Metadata
    product_url: HttpUrl
    scraped_at: datetime
    data_quality_score: float  # 0.0-1.0

    # Source Audit
    source_method: str  # "web_scrape"
    scraper_version: str
    confidence_level: str  # "high", "medium", "low"

class PricingSnapshot(BaseModel):
    """Price tracking over time"""
    product_id: str
    retailer: str
    price: Decimal
    in_stock: bool
    snapshot_date: datetime

class CategoryData(BaseModel):
    """Aggregated category insights"""
    category_name: str
    subcategory: Optional[str] = None
    product_count: int
    price_range: Tuple[Decimal, Decimal]
    average_price: Decimal
    median_price: Decimal
    top_brands: List[str]
    collected_at: datetime
```

---

## ðŸ”„ WORKFLOW & ORCHESTRATION

### **1. Search & Discovery**
```python
def discover_products(category: str, retailer: str, limit: int = 100):
    """
    1. Perform search query on retailer site
    2. Extract product links from search results
    3. Paginate through results (respect limits)
    4. Return list of product URLs
    """
```

### **2. Product Detail Scraping**
```python
async def scrape_product(url: str, retailer: str) -> ProductData:
    """
    1. Fetch product page with StealthyFetcher
    2. Extract structured data
    3. Validate with Pydantic model
    4. Cache response (24 hours)
    5. Return ProductData or None if failed
    """
```

### **3. Batch Processing**
```python
async def scrape_batch(urls: List[str], max_concurrent: int = 2):
    """
    1. Create async tasks for each URL
    2. Limit concurrent requests per domain
    3. Add delays between batches
    4. Collect results
    5. Handle errors gracefully
    """
```

### **4. Data Aggregation**
```python
def aggregate_pricing(products: List[ProductData]) -> CategoryData:
    """
    1. Group products by category/subcategory
    2. Calculate statistics (avg, median, range)
    3. Identify top brands
    4. Generate insights
    """
```

---

## ðŸ’¾ STORAGE STRATEGY

### **SQLite Database Schema**

```sql
CREATE TABLE products (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    retailer TEXT NOT NULL,
    product_id TEXT NOT NULL,
    name TEXT NOT NULL,
    brand TEXT,
    current_price REAL NOT NULL,
    rating REAL,
    review_count INTEGER,
    in_stock BOOLEAN,
    product_url TEXT NOT NULL,
    scraped_at TIMESTAMP NOT NULL,
    data_json TEXT NOT NULL,  -- Full JSON blob
    UNIQUE(retailer, product_id)
);

CREATE TABLE price_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    product_id INTEGER REFERENCES products(id),
    price REAL NOT NULL,
    in_stock BOOLEAN,
    snapshot_date TIMESTAMP NOT NULL
);

CREATE TABLE scrape_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    retailer TEXT NOT NULL,
    url TEXT NOT NULL,
    status_code INTEGER,
    success BOOLEAN,
    error_message TEXT,
    duration_ms INTEGER,
    scraped_at TIMESTAMP NOT NULL
);

CREATE INDEX idx_products_retailer_brand ON products(retailer, brand);
CREATE INDEX idx_products_scraped_at ON products(scraped_at);
CREATE INDEX idx_price_history_date ON price_history(snapshot_date);
```

---

## ðŸš€ IMPLEMENTATION PLAN

### **Phase 1: Foundation** (Current)
- âœ… Install Scrapling + Camoufox
- âœ… Test basic scraping functionality
- âœ… Design architecture
- â³ Implement base scraper class
- â³ Implement data models
- â³ Set up SQLite database

### **Phase 2: Retailer Scrapers**
- â³ Implement HomeDepotScraper
- â³ Implement LowesScraper
- â³ Implement AmazonScraper
- â³ Test each scraper individually

### **Phase 3: Reliability & Scale**
- â³ Add rate limiting
- â³ Add retry logic with backoff
- â³ Implement caching
- â³ Add error handling & logging
- â³ Test at scale (100+ products)

### **Phase 4: Integration**
- â³ Integrate with category_intelligence module
- â³ Update pricing_analyzer to use real data
- â³ Update brand_discovery to use real data
- â³ Generate report with 100% real data

---

## ðŸ“ USAGE EXAMPLES

### **Example 1: Scrape Home Depot Products**
```python
from modules.category_intelligence.scrapers import HomeDepotScraper

scraper = HomeDepotScraper()
products = await scraper.search("garage storage shelving", limit=50)

for product in products:
    print(f"{product.name}: ${product.current_price}")
    print(f"  Rating: {product.rating} ({product.review_count} reviews)")
    print(f"  In Stock: {product.in_stock}")
```

### **Example 2: Compare Prices Across Retailers**
```python
from modules.category_intelligence.scrapers import ScrapingOrchestrator

orchestrator = ScrapingOrchestrator()
results = await orchestrator.search_multi_retailer(
    query="garage storage bins",
    retailers=["homedepot", "lowes", "amazon"],
    limit_per_retailer=30
)

# Results aggregated by product similarity
for product_group in results.similar_products:
    print(f"\nSimilar product across retailers:")
    for variant in product_group:
        print(f"  {variant.retailer}: ${variant.current_price}")
```

### **Example 3: Track Prices Over Time**
```python
from modules.category_intelligence.scrapers import PriceTracker

tracker = PriceTracker()
await tracker.track_product(
    retailer="homedepot",
    product_id="12345",
    frequency="daily"  # daily, weekly, monthly
)

# Get price history
history = tracker.get_price_history(product_id="12345", days=30)
```

---

## âš ï¸ LEGAL & ETHICAL CONSIDERATIONS

### **Terms of Service Compliance**
- âœ… Review each retailer's ToS
- âœ… Obey robots.txt directives
- âœ… Rate limit to avoid server strain
- âœ… Don't use for competitive pricing automation (use for research only)
- âœ… Don't redistribute scraped data commercially

### **Respectful Crawling**
- âœ… Identify as legitimate research tool (User-Agent)
- âœ… Cache aggressively to minimize requests
- âœ… Never DDoS or overload servers
- âœ… Respect 429 (Rate Limit) responses immediately
- âœ… Provide contact info in User-Agent

### **Data Privacy**
- âœ… Only collect public product data
- âœ… Don't collect user reviews with PII
- âœ… Don't collect customer purchase data
- âœ… Comply with GDPR/CCPA for any user data

---

## ðŸ“Š PERFORMANCE TARGETS

| Metric | Target | Rationale |
|--------|--------|-----------|
| Products/hour | 500-1000 | Respectful rate limiting |
| Success rate | >90% | With retry logic & anti-detection |
| Cache hit rate | >70% | Reduce load on retailers |
| Data accuracy | >95% | Pydantic validation |
| Scraper uptime | >98% | Graceful error handling |
| Response time | <5s avg | StealthyFetcher performance |

---

## ðŸ” MONITORING & MAINTENANCE

### **Health Checks**
- Daily: Test each scraper with known product
- Weekly: Validate selector still works
- Monthly: Review blocked requests & adjust

### **Alerts**
- Success rate drops below 80%
- Repeated 403/429 errors
- Selector failures (adaptive mode fallback)

### **Maintenance**
- Update selectors when sites change
- Review and update anti-detection strategies
- Prune old cache data (>30 days)
- Archive price history (>90 days to cold storage)

---

## ðŸ“š REFERENCES

- **Scrapling Docs**: https://scrapling.readthedocs.io
- **Camoufox**: Anti-detection Firefox fork
- **Web Scraping Best Practices 2025**: https://substack.thewebscraping.club/p/the-2025-web-scraping-tech-stack
- **robots.txt Spec**: https://www.robotstxt.org/

---

**Status**: Ready for Implementation
**Next Step**: Implement base scraper infrastructure
